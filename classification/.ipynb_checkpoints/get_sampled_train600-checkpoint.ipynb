{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c542b19-1f48-48e6-8dd4-889d32183c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd #For reading csv files.\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt #For plotting.\n",
    "\n",
    "import PIL.Image as Image #For working with image files.\n",
    "\n",
    "#Importing torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset,DataLoader #For working with data.\n",
    "\n",
    "from torchvision import models,transforms #For pretrained models,image transformations.\n",
    "import tqdm\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') #Use GPU if it's available or else use CPU.\n",
    "print(device) #Prints the device we're using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "164461b5-e3b7-4eec-8806-b5be9ab79e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class aptos_dataset(Dataset): # Inherits from the Dataset class.\n",
    "#     '''\n",
    "#     dataset class overloads the __init__, __len__, __getitem__ methods of the Dataset class. \n",
    "    \n",
    "#     Attributes :\n",
    "#         df:  DataFrame object for the csv file.\n",
    "#         data_path: Location of the dataset.\n",
    "#         image_transform: Transformations to apply to the image.\n",
    "#         train: A boolean indicating whether it is a training_set or not.\n",
    "#     '''\n",
    "    \n",
    "#     def __init__(self,df,data_path,normalized_labels,image_transform=None,train=True): # Constructor.\n",
    "#         super(Dataset,self).__init__() #Calls the constructor of the Dataset class.\n",
    "#         self.df = df\n",
    "#         self.data_path = data_path\n",
    "#         self.image_transform = image_transform\n",
    "#         self.train = train\n",
    "#         self.normalized_labels = normalized_labels\n",
    "        \n",
    "#     def __len__(self):\n",
    "#         return len(self.df) #Returns the number of samples in the dataset.\n",
    "    \n",
    "#     def __getitem__(self,index):\n",
    "#         image_id = self.df['id_code'][index]\n",
    "#         image = Image.open(f'{self.data_path}/{image_id}.png') #Image.\n",
    "#         if self.image_transform :\n",
    "#             image = self.image_transform(image) #Applies transformation to the image.\n",
    "        \n",
    "#         if self.train :\n",
    "# #             label = self.df['diagnosis'][index] #Label.\n",
    "# #             label = self.df['centers'][index] # 얘만 잘 해보면?\n",
    "#             label = self.normalized_labels[index]\n",
    "#             return image,label #,image_id,index #If train == True, return image & label.\n",
    "        \n",
    "#         else:\n",
    "#             return image #If train != True, return image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d9c7b53-629c-40b8-bbba-ffa0a8d9a6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = pd.read_csv('/home/unix/mjeon/privacy/ICML2022/classification/labels/centroid_aptos_k5_W16.csv')\n",
    "# print(f'No.of.training_samples: {len(train_df)}')\n",
    "\n",
    "# valid_transform = transforms.Compose([transforms.Resize([224,224]),\n",
    "#                                       transforms.ToTensor()])\n",
    "\n",
    "# images_path = '/home/unix/mjeon/privacy/ICML2022/classification/centroids/aptos/W16/k5_images'\n",
    "# normalized_labels = np.load('/home/unix/mjeon/privacy/ICML2022/classification/labels/k5_aptos_W16_normalized_labels.npy')\n",
    "# data_set = aptos_dataset(train_df,images_path,normalized_labels,image_transform=valid_transform)\n",
    "# train_dataloader = DataLoader(data_set,batch_size=32,shuffle=False, pin_memory=True, num_workers=8) #DataLoader for train_set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50771934-d1bd-4f09-b538-19a9260a6ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class aptos_dataset(Dataset): # Inherits from the Dataset class.\n",
    "    '''\n",
    "    dataset class overloads the __init__, __len__, __getitem__ methods of the Dataset class. \n",
    "    \n",
    "    Attributes :\n",
    "        df:  DataFrame object for the csv file.\n",
    "        data_path: Location of the dataset.\n",
    "        image_transform: Transformations to apply to the image.\n",
    "        train: A boolean indicating whether it is a training_set or not.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self,df,data_path,image_transform=None): # Constructor.\n",
    "        super(Dataset,self).__init__() #Calls the constructor of the Dataset class.\n",
    "        self.df = df\n",
    "        self.data_path = data_path\n",
    "        self.image_transform = image_transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df) #Returns the number of samples in the dataset.\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        # print('index:',index)\n",
    "        # print('self.df[id_code]:',self.df['id_code'])\n",
    "        image_id = self.df['id_code'][index]\n",
    "        image = Image.open(f'{self.data_path}/{image_id}.png') #Image.\n",
    "        if self.image_transform :\n",
    "            image = self.image_transform(image) #Applies transformation to the image.\n",
    "        \n",
    "#         label = self.df['diagnosis'][index] #Label.\n",
    "        return image#,label #If train == True, return image & label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "717b2114-4cf9-47f5-a4a6-0948972cc4b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No.of.training_samples: 600\n"
     ]
    }
   ],
   "source": [
    "# train_df = pd.read_csv('/home/minkyu/privacy/data/splited_val/aptos/sampled600_labels.csv')\n",
    "# print(f'No.of.training_samples: {len(train_df)}')\n",
    "\n",
    "# valid_transform = transforms.Compose([transforms.Resize([224,224]),\n",
    "#                                       transforms.ToTensor()])\n",
    "\n",
    "# images_path = '/home/minkyu/privacy/data/splited_val/aptos/sampled600'\n",
    "\n",
    "# data_set = aptos_dataset(train_df,images_path, image_transform=valid_transform)\n",
    "# train_dataloader = DataLoader(data_set,batch_size=32,shuffle=False, pin_memory=True, num_workers=8) #DataLoader for train_set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9316c0de-eb26-4d2c-91b9-3ffa0fb5ad09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No.of.training_samples: 600\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('/home/minkyu/privacy/ICML2022/classification/labels/aptos/centroid_whole_aptos_k5_W16.csv')\n",
    "print(f'No.of.training_samples: {len(train_df)}')\n",
    "\n",
    "valid_transform = transforms.Compose([transforms.Resize([224,224]),\n",
    "                                      transforms.ToTensor()])\n",
    "\n",
    "images_path = '/home/minkyu/privacy/ICML2022/classification/centroids/aptos/k5_images'\n",
    "\n",
    "data_set = aptos_dataset(train_df,images_path, image_transform=valid_transform)\n",
    "train_dataloader = DataLoader(data_set,batch_size=32,shuffle=False, pin_memory=True, num_workers=8) #DataLoader for train_set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "76372019-5da5-42cb-86fa-6ebec205c230",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_and_std(train_dataset, batch_size, num_workers):\n",
    "    loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    num_samples = 0.\n",
    "    channel_mean = torch.Tensor([0., 0., 0.])\n",
    "    channel_std = torch.Tensor([0., 0., 0.])\n",
    "    for samples in loader:\n",
    "        X = samples\n",
    "        channel_mean += X.mean((2, 3)).sum(0)\n",
    "        num_samples += X.size(0)\n",
    "    channel_mean /= num_samples\n",
    "\n",
    "    for samples in loader:\n",
    "        X = samples\n",
    "        batch_samples = X.size(0)\n",
    "        X = X.permute(0, 2, 3, 1).reshape(-1, 3)\n",
    "        channel_std += ((X - channel_mean) ** 2).mean(0) * batch_samples\n",
    "    channel_std = torch.sqrt(channel_std / num_samples)\n",
    "\n",
    "    mean, std = channel_mean.tolist(), channel_std.tolist()\n",
    "    print('mean: {}'.format(mean))\n",
    "    print('std: {}'.format(std))\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ed4537e6-46d2-41dd-848a-3b2208483d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: [0.41809403896331787, 0.22021695971488953, 0.06570685654878616]\n",
      "std: [0.2725280523300171, 0.1409672647714615, 0.06416250765323639]\n"
     ]
    }
   ],
   "source": [
    "mean, std = mean_and_std(data_set, batch_size=32, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46ab0649-fe55-4152-b54f-333bc6175ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_and_std(train_dataset, batch_size, num_workers):\n",
    "    loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    num_samples = 0.\n",
    "    channel_mean = torch.Tensor([0., 0., 0.])\n",
    "    channel_std = torch.Tensor([0., 0., 0.])\n",
    "    for samples in loader:\n",
    "        X, _ = samples\n",
    "        channel_mean += X.mean((2, 3)).sum(0)\n",
    "        num_samples += X.size(0)\n",
    "    channel_mean /= num_samples\n",
    "\n",
    "    for samples in loader:\n",
    "        X, _ = samples\n",
    "        batch_samples = X.size(0)\n",
    "        X = X.permute(0, 2, 3, 1).reshape(-1, 3)\n",
    "        channel_std += ((X - channel_mean) ** 2).mean(0) * batch_samples\n",
    "    channel_std = torch.sqrt(channel_std / num_samples)\n",
    "\n",
    "    mean, std = channel_mean.tolist(), channel_std.tolist()\n",
    "    print('mean: {}'.format(mean))\n",
    "    print('std: {}'.format(std))\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d2e6a3c-d40e-4b50-b01b-be5b4a1378b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: [0.4108440577983856, 0.22029855847358704, 0.07460451126098633]\n",
      "std: [0.27319756150245667, 0.15039442479610443, 0.08080754429101944]\n"
     ]
    }
   ],
   "source": [
    "mean, std = mean_and_std(data_set, batch_size=32, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2d0a5e23-dfdb-4bc3-b1a7-5d29b74c277d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = '/home/unix/mjeon/privacy/data/splited_val/aptos/aptos_val_3000.csv'\n",
    "test_image_path = '/home/unix/mjeon/privacy/data/splited_val/aptos/aptos_val_3000'\n",
    "\n",
    "# val_dataset = aptos_dataset(test_df, test_image_path, image_transform=test_transform)\n",
    "# test_dataset = aptos_dataset(test_df, test_image_path, image_transform=test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d8949dde-f88d-4dca-a379-86914eaf308d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'38487e1a5b1f'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(test_df)['id_code'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689e98e8-6be0-4403-b192-008be7e20245",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "privacy",
   "language": "python",
   "name": "privacy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
